{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5: Деревья решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# Настройка отображения графиков\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и предварительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1. ПРЕДВАРИТЕЛЬНАЯ ОБРАБОТКА ДАННЫХ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Загрузка датасета\n",
    "mushroom = fetch_ucirepo(id=73)\n",
    "\n",
    "# Данные\n",
    "X = mushroom.data.features\n",
    "y = mushroom.data.targets\n",
    "\n",
    "# Преобразуем целевую переменную в бинарный формат (0 - edible, 1 - poisonous)\n",
    "y_binary = (y[\"poisonous\"] == \"p\").astype(int)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna(\"unknown\")\n",
    "\n",
    "print(\"Информация о датасете:\")\n",
    "print(f\"Размерность признаков: {X.shape}\")\n",
    "print(f\"Размерность целевой переменной: {y_binary.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"Проверка отсутствующих значений:\")\n",
    "print(X.isnull().sum().sum())\n",
    "print()\n",
    "\n",
    "print(\"Первые 5 строк данных:\")\n",
    "print(pd.concat([X.head(), y_binary.head()], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Статистика и визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2. СТАТИСТИКА И ВИЗУАЛИЗАЦИЯ ДАННЫХ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Базовая статистика по целевой переменной\n",
    "print(\"Распределение классов:\")\n",
    "class_dist = Counter(y_binary)\n",
    "for cls, count in class_dist.items():\n",
    "    percentage = count / len(y_binary) * 100\n",
    "    label = \"poisonous\" if cls == 1 else \"edible\"\n",
    "    print(f\"{label}: {count} примеров ({percentage:.1f}%)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация распределения классов\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar([\"Edible\", \"Poisonous\"], [class_dist[0], class_dist[1]], color=[\"green\", \"red\"], alpha=0.7)\n",
    "plt.title(\"Распределение классов грибов\")\n",
    "plt.ylabel(\"Количество примеров\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"3. РЕАЛИЗАЦИЯ DecisionTree (НЕБИНАРНОЕ ДЕРЕВО)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Узел небинарного дерева решений\"\"\"\n",
    "\n",
    "    def __init__(self, feature=None, results=None, children=None):\n",
    "        self.feature = feature  # Признак для разделения\n",
    "        self.results = results  # Распределение классов (для листа)\n",
    "        self.children = children or {}  # Словарь: значение признака -> дочерний узел\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Небинарное дерево решений для классификации\"\"\"\n",
    "\n",
    "    def __init__(self, max_depth=10, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "\n",
    "    def calculate_gini(self, y):\n",
    "        \"\"\"Вычисление коэффициента Джини\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "\n",
    "        class_counts = Counter(y)\n",
    "        gini = 1.0\n",
    "\n",
    "        for count in class_counts.values():\n",
    "            probability = count / len(y)\n",
    "            gini -= probability**2\n",
    "\n",
    "        return gini\n",
    "\n",
    "    def split_data_multiway(self, X, y, feature):\n",
    "        \"\"\"\n",
    "        Разделение данных по всем уникальным значениям признака.\n",
    "        Возвращает словарь: значение -> (X_subset, y_subset)\n",
    "        \"\"\"\n",
    "        splits = {}\n",
    "\n",
    "        for i in range(len(X)):\n",
    "            value = X[i][feature]\n",
    "            if value not in splits:\n",
    "                splits[value] = ([], [])\n",
    "\n",
    "            splits[value][0].append(X[i])\n",
    "            splits[value][1].append(y[i])\n",
    "\n",
    "        return splits\n",
    "\n",
    "    def find_best_split(self, X, y, features):\n",
    "        \"\"\"\n",
    "        Поиск лучшего признака для разделения (многопутевое разделение).\n",
    "        Для каждого признака создаем ветвь для каждого уникального значения.\n",
    "        \"\"\"\n",
    "        best_gini = float(\"inf\")\n",
    "        best_feature = None\n",
    "        best_splits = None\n",
    "\n",
    "        current_gini = self.calculate_gini(y)\n",
    "\n",
    "        for feature in features:\n",
    "            # Разделяем данные по всем уникальным значениям признака\n",
    "            splits = self.split_data_multiway(X, y, feature)\n",
    "\n",
    "            # Пропускаем признаки с единственным значением\n",
    "            if len(splits) <= 1:\n",
    "                continue\n",
    "\n",
    "            # Вычисляем взвешенный коэффициент Джини\n",
    "            weighted_gini = 0\n",
    "            for value, (X_subset, y_subset) in splits.items():\n",
    "                weight = len(y_subset) / len(y)\n",
    "                weighted_gini += weight * self.calculate_gini(y_subset)\n",
    "\n",
    "            # Выбираем лучшее разделение\n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                best_feature = feature\n",
    "                best_splits = splits\n",
    "\n",
    "        # Если улучшение незначительное, не разделяем\n",
    "        if best_gini >= current_gini - 0.001:\n",
    "            return None, None\n",
    "\n",
    "        return best_feature, best_splits\n",
    "\n",
    "    def build_tree(self, X, y, feature s, depth=0):\n",
    "        \"\"\"Рекурсивное построение небинарного дерева\"\"\"\n",
    "\n",
    "        # Базовые случаи остановки\n",
    "        if len(y) < self.min_samples_split or depth >= self.max_depth or len(set(y)) == 1:\n",
    "            return Node(results=Counter(y))\n",
    "\n",
    "        # Поиск лучшего разделения\n",
    "        feature, splits = self.find_best_split(X, y, features)\n",
    "\n",
    "        if feature is None:\n",
    "            return Node(results=Counter(y))\n",
    "\n",
    "        # Создаем дочерние узлы для каждого значения признака\n",
    "        children = {}\n",
    "        for value, (X_subset, y_subset) in splits.items():\n",
    "            children[value] = self.build_tree(X_subset, y_subset, features, depth + 1)\n",
    "\n",
    "        return Node(feature=feature, children=children)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение дерева\"\"\"\n",
    "        # Преобразуем DataFrame в список словарей для удобства\n",
    "        X_list = X.to_dict(\"records\")\n",
    "        y_list = y.tolist()\n",
    "\n",
    "        features = list(X.columns)\n",
    "\n",
    "        self.root = self.build_tree(X_list, y_list, features)\n",
    "\n",
    "    def predict_single(self, x):\n",
    "        \"\"\"Предсказание для одного примера\"\"\"\n",
    "        node = self.root\n",
    "\n",
    "        while node.children:\n",
    "            feature_value = x[node.feature]\n",
    "\n",
    "            # Ищем соответствующую ветвь по значению признака\n",
    "            if feature_value in node.children:\n",
    "                node = node.children[feature_value]\n",
    "            else:\n",
    "                # Если значение не встречалось при обучении, возвращаем наиболее частый класс\n",
    "                break\n",
    "\n",
    "        # Возвращаем наиболее частый класс\n",
    "        if node.results:\n",
    "            return max(node.results.items(), key=lambda x: x[1])[0]\n",
    "        return 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для набора данных\"\"\"\n",
    "        X_list = X.to_dict(\"records\")\n",
    "        return [self.predict_single(x) for x in X_list]\n",
    "\n",
    "    def predict_proba_single(self, x):\n",
    "        \"\"\"Вероятности классов для одного примера\"\"\"\n",
    "        node = self.root\n",
    "\n",
    "        while node.children:\n",
    "            feature_value = x[node.feature]\n",
    "\n",
    "            if feature_value in node.children:\n",
    "                node = node.children[feature_value]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if node.results:\n",
    "            total = sum(node.results.values())\n",
    "            proba_1 = node.results.get(1, 0) / total\n",
    "            return [1 - proba_1, proba_1]\n",
    "        return [0.5, 0.5]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Вероятности классов для набора данных\"\"\"\n",
    "        X_list = X.to_dict(\"records\")\n",
    "        probabilities = []\n",
    "\n",
    "        for x in X_list:\n",
    "            proba = self.predict_proba_single(x)\n",
    "            probabilities.append(proba[1])  # Вероятность класса 1\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "print(\"Класс DecisionTree (небинарное дерево) успешно реализован\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Отбор признаков и построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4. ОТБОР ПРИЗНАКОВ И ПОСТРОЕНИЕ МОДЕЛИ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Устанавливаем seed для воспроизводимости результатов\n",
    "random.seed(413732)\n",
    "\n",
    "\n",
    "def select_features(X, method=\"sqrt\"):\n",
    "    \"\"\"\n",
    "    Отбор признаков для дерева решений\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "\n",
    "    if method == \"sqrt\":\n",
    "        n_selected = int(math.sqrt(n_features))\n",
    "    else:\n",
    "        n_selected = n_features\n",
    "\n",
    "    selected_indices = random.sample(range(n_features), n_selected)\n",
    "    selected_features = X.columns[selected_indices].tolist()\n",
    "\n",
    "    return selected_features, selected_indices\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    \"\"\"Разделение на обучающую и тестовую выборки\"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    n = len(X)\n",
    "    test_indices = np.random.choice(n, size=int(n * test_size), replace=False)\n",
    "    train_indices = np.setdiff1d(np.arange(n), test_indices)\n",
    "\n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Отбор признаков\n",
    "selected_features, selected_indices = select_features(X)\n",
    "X_selected = X[selected_features].copy()\n",
    "\n",
    "print(f\"Отобрано {len(selected_features)} признаков из {X.shape[1]}:\")\n",
    "print(selected_features)\n",
    "print()\n",
    "\n",
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected,\n",
    "    y_binary,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(f\"Обучающая выборка: {len(X_train)} примеров\")\n",
    "print(f\"Тестовая выборка: {len(X_test)} примеров\")\n",
    "print()\n",
    "\n",
    "# Обучение модели\n",
    "tree = DecisionTree(max_depth=5, min_samples_split=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Модель дерева решений успешно обучена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5. ОЦЕНКА МОДЕЛИ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Вычисление метрик без использования библиотек\"\"\"\n",
    "    tp = fp = tn = fn = 0\n",
    "\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == 1 and pred == 1:\n",
    "            tp += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            fp += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            tn += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            fn += 1\n",
    "\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall, tp, fp, tn, fn\n",
    "\n",
    "\n",
    "def calculate_auc_roc(y_true, y_proba):\n",
    "    # Сортируем по убыванию вероятности\n",
    "    data = sorted(zip(y_proba, y_true), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Инициализация\n",
    "    tpr_list = [0]\n",
    "    fpr_list = [0]\n",
    "\n",
    "    tp = fp = 0\n",
    "    total_p = sum(y_true)\n",
    "    total_n = len(y_true) - total_p\n",
    "\n",
    "    last_prob = None\n",
    "\n",
    "    for prob, true in data:\n",
    "        if prob != last_prob:\n",
    "            tpr = tp / total_p if total_p > 0 else 0\n",
    "            fpr = fp / total_n if total_n > 0 else 0\n",
    "            tpr_list.append(tpr)\n",
    "            fpr_list.append(fpr)\n",
    "            last_prob = prob\n",
    "\n",
    "        if true == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    # Добавляем конечную точку\n",
    "    tpr_list.append(1)\n",
    "    fpr_list.append(1)\n",
    "\n",
    "    # Вычисление AUC методом трапеций\n",
    "    auc = 0\n",
    "    for i in range(1, len(tpr_list)):\n",
    "        auc += (fpr_list[i] - fpr_list[i - 1]) * (tpr_list[i] + tpr_list[i - 1]) / 2\n",
    "\n",
    "    return fpr_list, tpr_list, auc\n",
    "\n",
    "\n",
    "def calculate_auc_pr(y_true, y_proba):\n",
    "    # Сортируем по убыванию вероятности\n",
    "    data = sorted(zip(y_proba, y_true), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "\n",
    "    tp = fp = 0\n",
    "    total_p = sum(y_true)\n",
    "\n",
    "    for prob, true in data:\n",
    "        if true == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 1\n",
    "        recall = tp / total_p if total_p > 0 else 0\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "    # Вычисление AUC методом трапеций\n",
    "    auc_pr = 0\n",
    "    for i in range(1, len(precision_list)):\n",
    "        auc_pr += (\n",
    "            (recall_list[i] - recall_list[i - 1]) * (precision_list[i] + precision_list[i - 1]) / 2\n",
    "        )\n",
    "\n",
    "    return precision_list, recall_list, auc_pr\n",
    "\n",
    "\n",
    "# Предсказания\n",
    "y_pred = tree.predict(X_test)\n",
    "y_proba = tree.predict_proba(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy, precision, recall, tp, fp, tn, fn = calculate_metrics(y_test.values, y_pred)\n",
    "\n",
    "print(\"РЕЗУЛЬТАТЫ ОЦЕНКИ:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"МАТРИЦА ОШИБОК:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"TP: {tp}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TN: {tn}\")\n",
    "print()\n",
    "\n",
    "# Визуализация матрицы ошибок\n",
    "confusion_matrix = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.imshow(confusion_matrix, interpolation=\"nearest\", cmap=plt.cm.Blues)\n",
    "plt.title(\"Матрица ошибок\")\n",
    "plt.colorbar()\n",
    "\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, [\"Predicted 0\", \"Predicted 1\"])\n",
    "plt.yticks(tick_marks, [\"Actual 0\", \"Actual 1\"])\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(\n",
    "            j,\n",
    "            i,\n",
    "            str(confusion_matrix[i, j]),\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if confusion_matrix[i, j] > confusion_matrix.max() / 2 else \"black\",\n",
    "        )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"КРИВЫЕ КАЧЕСТВА:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Вычисление AUC-ROC\n",
    "fpr, tpr, auc_roc = calculate_auc_roc(y_test.values, y_proba)\n",
    "\n",
    "# Вычисление AUC-PR\n",
    "precision_curve, recall_curve, auc_pr = calculate_auc_pr(y_test.values, y_proba)\n",
    "\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "print()\n",
    "\n",
    "# Построение графиков\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC-кривая\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, \"b-\", linewidth=2, label=f\"ROC curve (AUC = {auc_roc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], \"r--\", linewidth=1, label=\"Random classifier\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# PR-кривая\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_curve, precision_curve, \"g-\", linewidth=2, label=f\"PR curve (AUC = {auc_pr:.4f})\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"6. ВЫВОДЫ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP) — точность положительных прогнозов\n",
    "# Recall = TP / (TP + FN) — полнота обнаружения положительных\n",
    "\n",
    "print(\"\\nОСНОВНЫЕ РЕЗУЛЬТАТЫ:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"• Точность модели: {accuracy:.4f}\")\n",
    "print(f\"• Precision: {precision:.4f}\")\n",
    "print(f\"• Recall: {recall:.4f}\")\n",
    "print(f\"• AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"• AUC-PR: {auc_pr:.4f}\")\n",
    "\n",
    "print(\"\\nХАРАКТЕРИСТИКИ МОДЕЛИ:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"• Количество признаков: {len(selected_features)}\")\n",
    "print(f\"• Максимальная глубина дерева: {tree.max_depth}\")\n",
    "print(f\"• Минимальное количество samples для разделения: {tree.min_samples_split}\")\n",
    "print(f\"• Размер тестовой выборки: {len(X_test)} примеров\")\n",
    "\n",
    "print(\"\\nРАСПРЕДЕЛЕНИЕ КЛАССОВ В ТЕСТОВОЙ ВЫБОРКЕ:\")\n",
    "print(\"-\" * 30)\n",
    "test_class_dist = Counter(y_test)\n",
    "for cls, count in test_class_dist.items():\n",
    "    percentage = count / len(y_test) * 100\n",
    "    label = \"poisonous\" if cls == 1 else \"edible\"\n",
    "    print(f\"• {label}: {count} примеров ({percentage:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
