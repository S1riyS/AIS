{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 5. Деревья решений\n",
    "## Классификация грибов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import math\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка датасета\n",
    "mushroom = fetch_ucirepo(id=73) \n",
    "\n",
    "# Данные\n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "\n",
    "# Преобразуем целевую переменную в бинарный формат (0 - edible, 1 - poisonous)\n",
    "y_binary = (y['poisonous'] == 'p').astype(int)\n",
    "\n",
    "# Обработка пропущенных значений\n",
    "X = X.fillna('unknown')\n",
    "\n",
    "print(\"Размерность данных:\", X.shape)\n",
    "print(\"\\nПервые 5 строк:\")\n",
    "print(pd.concat([X.head(), y_binary.head()], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Отбор признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, method='sqrt'):\n",
    "    \"\"\"\n",
    "    Отбор признаков для дерева решений\n",
    "    \"\"\"\n",
    "    n_features = X.shape[1]\n",
    "    \n",
    "    if method == 'sqrt':\n",
    "        n_selected = int(math.sqrt(n_features))\n",
    "    else:\n",
    "        n_selected = n_features\n",
    "    \n",
    "    selected_indices = random.sample(range(n_features), n_selected)\n",
    "    selected_features = X.columns[selected_indices].tolist()\n",
    "    \n",
    "    print(f\"Отобрано {n_selected} признаков из {n_features}:\")\n",
    "    print(selected_features)\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор признаков\n",
    "selected_features = select_features(X)\n",
    "X_selected = X[selected_features].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Узел дерева решений\"\"\"\n",
    "    def __init__(self, feature=None, value=None, results=None, children=None):\n",
    "        self.feature = feature      # Признак для разделения\n",
    "        self.value = value          # Значение признака\n",
    "        self.results = results      # Распределение классов (для листа)\n",
    "        self.children = children or []  # Дочерние узлы\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Дерево решений для классификации\"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=10, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "    \n",
    "    def calculate_gini(self, y):\n",
    "        \"\"\"Вычисление коэффициента Джини\"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        \n",
    "        class_counts = Counter(y)\n",
    "        gini = 1.0\n",
    "        \n",
    "        for count in class_counts.values():\n",
    "            probability = count / len(y)\n",
    "            gini -= probability ** 2\n",
    "            \n",
    "        return gini\n",
    "    \n",
    "    def split_data(self, X, y, feature, value):\n",
    "        \"\"\"Разделение данных по значению признака\"\"\"\n",
    "        left_X, left_y = [], []\n",
    "        right_X, right_y = [], []\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            if X[i][feature] == value:\n",
    "                left_X.append(X[i])\n",
    "                left_y.append(y[i])\n",
    "            else:\n",
    "                right_X.append(X[i])\n",
    "                right_y.append(y[i])\n",
    "                \n",
    "        return left_X, left_y, right_X, right_y\n",
    "    \n",
    "    def find_best_split(self, X, y, features):\n",
    "        \"\"\"Поиск лучшего разделения\"\"\"\n",
    "        best_gini = float('inf')\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "        best_splits = None\n",
    "        \n",
    "        current_gini = self.calculate_gini(y)\n",
    "        \n",
    "        for feature in features:\n",
    "            # Получаем все уникальные значения признака\n",
    "            values = set([x[feature] for x in X])\n",
    "            \n",
    "            for value in values:\n",
    "                left_X, left_y, right_X, right_y = self.split_data(X, y, feature, value)\n",
    "                \n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Взвешенный коэффициент Джини\n",
    "                left_weight = len(left_y) / len(y)\n",
    "                right_weight = len(right_y) / len(y)\n",
    "                \n",
    "                weighted_gini = (left_weight * self.calculate_gini(left_y) + \n",
    "                               right_weight * self.calculate_gini(right_y))\n",
    "                \n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    best_feature = feature\n",
    "                    best_value = value\n",
    "                    best_splits = (left_X, left_y, right_X, right_y)\n",
    "        \n",
    "        # Если улучшение незначительное, не разделяем\n",
    "        if best_gini >= current_gini - 0.001:\n",
    "            return None, None, None\n",
    "            \n",
    "        return best_feature, best_value, best_splits\n",
    "    \n",
    "    def build_tree(self, X, y, features, depth=0):\n",
    "        \"\"\"Рекурсивное построение дерева\"\"\"\n",
    "        \n",
    "        # Базовые случаи остановки\n",
    "        if (len(y) < self.min_samples_split or \n",
    "            depth >= self.max_depth or \n",
    "            len(set(y)) == 1):\n",
    "            \n",
    "            return Node(results=Counter(y))\n",
    "        \n",
    "        # Поиск лучшего разделения\n",
    "        feature, value, splits = self.find_best_split(X, y, features)\n",
    "        \n",
    "        if feature is None:\n",
    "            return Node(results=Counter(y))\n",
    "        \n",
    "        left_X, left_y, right_X, right_y = splits\n",
    "        \n",
    "        # Рекурсивное построение дочерних узлов\n",
    "        left_child = self.build_tree(left_X, left_y, features, depth + 1)\n",
    "        right_child = self.build_tree(right_X, right_y, features, depth + 1)\n",
    "        \n",
    "        return Node(feature=feature, value=value, children=[left_child, right_child])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение дерева\"\"\"\n",
    "        # Преобразуем DataFrame в список словарей для удобства\n",
    "        X_list = X.to_dict('records')\n",
    "        y_list = y.tolist()\n",
    "        \n",
    "        features = list(X.columns)\n",
    "        \n",
    "        self.root = self.build_tree(X_list, y_list, features)\n",
    "    \n",
    "    def predict_single(self, x):\n",
    "        \"\"\"Предсказание для одного примера\"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        while node.children:\n",
    "            if x[node.feature] == node.value:\n",
    "                node = node.children[0]  # Левый ребенок\n",
    "            else:\n",
    "                node = node.children[1]  # Правый ребенок\n",
    "        \n",
    "        # Возвращаем наиболее частый класс\n",
    "        if node.results:\n",
    "            return max(node.results.items(), key=lambda x: x[1])[0]\n",
    "        return 0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание для набора данных\"\"\"\n",
    "        X_list = X.to_dict('records')\n",
    "        return [self.predict_single(x) for x in X_list]\n",
    "    \n",
    "    def predict_proba_single(self, x):\n",
    "        \"\"\"Вероятности классов для одного примера\"\"\"\n",
    "        node = self.root\n",
    "        \n",
    "        while node.children:\n",
    "            if x[node.feature] == node.value:\n",
    "                node = node.children[0]\n",
    "            else:\n",
    "                node = node.children[1]\n",
    "        \n",
    "        if node.results:\n",
    "            total = sum(node.results.values())\n",
    "            proba_1 = node.results.get(1, 0) / total\n",
    "            return [1 - proba_1, proba_1]\n",
    "        return [0.5, 0.5]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Вероятности классов для набора данных\"\"\"\n",
    "        X_list = X.to_dict('records')\n",
    "        probabilities = []\n",
    "        \n",
    "        for x in X_list:\n",
    "            proba = self.predict_proba_single(x)\n",
    "            probabilities.append(proba[1])  # Вероятность класса 1\n",
    "        \n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучение и оценка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.3, random_state=None):\n",
    "    \"\"\"Разделение на обучающую и тестовую выборки\"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    n = len(X)\n",
    "    test_indices = np.random.choice(n, size=int(n * test_size), replace=False)\n",
    "    train_indices = np.setdiff1d(np.arange(n), test_indices)\n",
    "    \n",
    "    X_train = X.iloc[train_indices]\n",
    "    X_test = X.iloc[test_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    y_test = y.iloc[test_indices]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Вычисление метрик без использования библиотек\"\"\"\n",
    "    tp = fp = tn = fn = 0\n",
    "    \n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        if true == 1 and pred == 1:\n",
    "            tp += 1\n",
    "        elif true == 0 and pred == 1:\n",
    "            fp += 1\n",
    "        elif true == 0 and pred == 0:\n",
    "            tn += 1\n",
    "        elif true == 1 and pred == 0:\n",
    "            fn += 1\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) > 0 else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_binary, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Обучающая выборка: {len(X_train)} примеров\")\n",
    "print(f\"Тестовая выборка: {len(X_test)} примеров\")\n",
    "\n",
    "# Обучение модели\n",
    "tree = DecisionTree(max_depth=5, min_samples_split=10)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = tree.predict(X_test)\n",
    "y_proba = tree.predict_proba(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "accuracy, precision, recall, tp, fp, tn, fn = calculate_metrics(y_test.values, y_pred)\n",
    "\n",
    "print(\"\\nРезультаты оценки:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"\\nМатрица ошибок:\")\n",
    "print(f\"TP: {tp}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TN: {tn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Построение кривых AUC-ROC и AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc_roc(y_true, y_proba):\n",
    "    \"\"\"Вычисление AUC-ROC без использования библиотек\"\"\"\n",
    "    # Сортируем по убыванию вероятности\n",
    "    data = sorted(zip(y_proba, y_true), key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Инициализация\n",
    "    tpr_list = [0]\n",
    "    fpr_list = [0]\n",
    "    \n",
    "    tp = fp = 0\n",
    "    total_p = sum(y_true)\n",
    "    total_n = len(y_true) - total_p\n",
    "    \n",
    "    last_prob = None\n",
    "    \n",
    "    for prob, true in data:\n",
    "        if prob != last_prob:\n",
    "            tpr = tp / total_p if total_p > 0 else 0\n",
    "            fpr = fp / total_n if total_n > 0 else 0\n",
    "            tpr_list.append(tpr)\n",
    "            fpr_list.append(fpr)\n",
    "            last_prob = prob\n",
    "        \n",
    "        if true == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    \n",
    "    # Добавляем конечную точку\n",
    "    tpr_list.append(1)\n",
    "    fpr_list.append(1)\n",
    "    \n",
    "    # Вычисление AUC методом трапеций\n",
    "    auc = 0\n",
    "    for i in range(1, len(tpr_list)):\n",
    "        auc += (fpr_list[i] - fpr_list[i-1]) * (tpr_list[i] + tpr_list[i-1]) / 2\n",
    "    \n",
    "    return fpr_list, tpr_list, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc_pr(y_true, y_proba):\n",
    "    \"\"\"Вычисление AUC-PR без использования библиотек\"\"\"\n",
    "    # Сортируем по убыванию вероятности\n",
    "    data = sorted(zip(y_proba, y_true), key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    tp = fp = 0\n",
    "    total_p = sum(y_true)\n",
    "    \n",
    "    for prob, true in data:\n",
    "        if true == 1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 1\n",
    "        recall = tp / total_p if total_p > 0 else 0\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    # Вычисление AUC методом трапеций\n",
    "    auc_pr = 0\n",
    "    for i in range(1, len(precision_list)):\n",
    "        auc_pr += (recall_list[i] - recall_list[i-1]) * (precision_list[i] + precision_list[i-1]) / 2\n",
    "    \n",
    "    return precision_list, recall_list, auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление AUC-ROC\n",
    "fpr, tpr, auc_roc = calculate_auc_roc(y_test.values, y_proba)\n",
    "\n",
    "# Вычисление AUC-PR\n",
    "precision_curve, recall_curve, auc_pr = calculate_auc_pr(y_test.values, y_proba)\n",
    "\n",
    "print(\"Площади под кривыми:\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR: {auc_pr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построение графиков\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC-кривая\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, 'b-', label=f'ROC curve (AUC = {auc_roc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# PR-кривая\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall_curve, precision_curve, 'g-', label=f'PR curve (AUC = {auc_pr:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Дополнительная информация о модели\n",
    "print(\"\\nДополнительная информация:\")\n",
    "print(f\"Количество признаков: {len(selected_features)}\")\n",
    "print(f\"Максимальная глубина дерева: {tree.max_depth}\")\n",
    "print(f\"Минимальное количество samples для разделения: {tree.min_samples_split}\")\n",
    "print(f\"Размер тестовой выборки: {len(X_test)} примеров\")\n",
    "\n",
    "# Распределение классов в тестовой выборке\n",
    "class_dist = Counter(y_test)\n",
    "print(f\"\\nРаспределение классов в тестовой выборке:\")\n",
    "print(f\"Class 0 (edible): {class_dist[0]} примеров ({class_dist[0]/len(y_test)*100:.1f}%)\")\n",
    "print(f\"Class 1 (poisonous): {class_dist[1]} примеров ({class_dist[1]/len(y_test)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab5-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
